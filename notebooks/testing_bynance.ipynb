{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>num_trades</th>\n",
       "      <th>target</th>\n",
       "      <th>price_diff1</th>\n",
       "      <th>price_diff2</th>\n",
       "      <th>price_diff3</th>\n",
       "      <th>price_diff4</th>\n",
       "      <th>avg_vol</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:00</th>\n",
       "      <td>46216.93</td>\n",
       "      <td>46731.39</td>\n",
       "      <td>46208.37</td>\n",
       "      <td>46656.13</td>\n",
       "      <td>1503.33095</td>\n",
       "      <td>38608.0</td>\n",
       "      <td>46778.14</td>\n",
       "      <td>514.46</td>\n",
       "      <td>523.02</td>\n",
       "      <td>-8.56</td>\n",
       "      <td>439.2</td>\n",
       "      <td>0.038938</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 01:00:00</th>\n",
       "      <td>46656.14</td>\n",
       "      <td>46949.99</td>\n",
       "      <td>46574.06</td>\n",
       "      <td>46778.14</td>\n",
       "      <td>943.81539</td>\n",
       "      <td>31872.0</td>\n",
       "      <td>46811.77</td>\n",
       "      <td>293.85</td>\n",
       "      <td>375.93</td>\n",
       "      <td>-82.08</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.029613</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         open      high       low     close      volume  \\\n",
       "Unnamed: 0                                                                \n",
       "2022-01-01 00:00:00  46216.93  46731.39  46208.37  46656.13  1503.33095   \n",
       "2022-01-01 01:00:00  46656.14  46949.99  46574.06  46778.14   943.81539   \n",
       "\n",
       "                     num_trades    target  price_diff1  price_diff2  \\\n",
       "Unnamed: 0                                                            \n",
       "2022-01-01 00:00:00     38608.0  46778.14       514.46       523.02   \n",
       "2022-01-01 01:00:00     31872.0  46811.77       293.85       375.93   \n",
       "\n",
       "                     price_diff3  price_diff4   avg_vol  hour  day  month  \\\n",
       "Unnamed: 0                                                                  \n",
       "2022-01-01 00:00:00        -8.56        439.2  0.038938     0    1      1   \n",
       "2022-01-01 01:00:00       -82.08        122.0  0.029613     1    1      1   \n",
       "\n",
       "                     day_of_week  year  \n",
       "Unnamed: 0                              \n",
       "2022-01-01 00:00:00            5     0  \n",
       "2022-01-01 01:00:00            5     0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "df = pd.read_csv(\"btc_1h_data.csv\")\n",
    "df = df.set_index('Unnamed: 0')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df = df.drop(['close_time', 'qav', 'taker_base_vol', 'taker_quote_vol', 'ignore', 'open_time'], axis=1)\n",
    "\n",
    "def generate_features(df):\n",
    "    df_n = df.copy()\n",
    "    df_n[f\"target\"] = df_n[\"open\"].shift(-2)\n",
    "    #for n in range(1, n_lags):\n",
    "        #df_n[f\"lag{n}\"] = df_n[\"open\"].shift(n)\n",
    "        #df_n[f\"diff_lag{n}\"] = df_n[\"open\"] - df_n[f\"lag{n}\"]\n",
    "    df_n = df_n.iloc[:-2]\n",
    "\n",
    "    df_n['price_diff1'] = df_n['high'] - df_n['open']\n",
    "    df_n['price_diff2'] = df_n['high'] - df_n['low']\n",
    "    df_n['price_diff3'] = df_n['low'] - df_n['open']\n",
    "    df_n['price_diff4'] = df_n['close'] - df_n['open']\n",
    "\n",
    "    df_n['avg_vol'] = df_n['volume']/df_n['num_trades']\n",
    "    return df_n\n",
    "    \n",
    "df = generate_features(df)\n",
    "\n",
    "df = (\n",
    "    df\n",
    "    .assign(minute = df.index.minute)\n",
    "    .assign(hour = df.index.hour)\n",
    "    .assign(day = df.index.day)\n",
    "    .assign(month = df.index.month)\n",
    "    .assign(week_of_year = df.index.week)\n",
    "    .assign(year = df.index.year)\n",
    "    )\n",
    "df.drop(columns=[\"week_of_year\"], inplace=True)\n",
    "df['year'] -= 2022\n",
    "df = df.iloc[0:10000]\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['target']\n",
    "prices_features = ['open', 'high', 'low', 'close']\n",
    "time_features = ['hour', 'day', 'day_of_week', 'month', 'year']\n",
    "other_features = ['volume', 'num_trades', 'avg_vol']\n",
    "diff_features = ['price_diff1', 'price_diff2', 'price_diff3', 'price_diff4']\n",
    "all_but_prices_and_time = other_features + diff_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_price = StandardScaler()\n",
    "scaler_everything_but_price = StandardScaler()\n",
    "scaler_price.fit(df[target])\n",
    "for feature in prices_features + target:\n",
    "    df.loc[:, [feature]] = scaler_price.transform(df.loc[:, [feature]])\n",
    "df[all_but_prices_and_time] = scaler_everything_but_price.fit_transform(df[all_but_prices_and_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:00</th>\n",
       "      <td>2.367626</td>\n",
       "      <td>2.432548</td>\n",
       "      <td>2.366545</td>\n",
       "      <td>2.423051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 01:00:00</th>\n",
       "      <td>2.423052</td>\n",
       "      <td>2.460135</td>\n",
       "      <td>2.412694</td>\n",
       "      <td>2.438448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         open      high       low     close\n",
       "Unnamed: 0                                                 \n",
       "2022-01-01 00:00:00  2.367626  2.432548  2.366545  2.423051\n",
       "2022-01-01 01:00:00  2.423052  2.460135  2.412694  2.438448"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[prices_features].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_diff1</th>\n",
       "      <th>price_diff2</th>\n",
       "      <th>price_diff3</th>\n",
       "      <th>price_diff4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:00</th>\n",
       "      <td>2.756100</td>\n",
       "      <td>1.467071</td>\n",
       "      <td>0.673547</td>\n",
       "      <td>2.566082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 01:00:00</th>\n",
       "      <td>1.264705</td>\n",
       "      <td>0.764807</td>\n",
       "      <td>0.180366</td>\n",
       "      <td>0.715912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     price_diff1  price_diff2  price_diff3  price_diff4\n",
       "Unnamed: 0                                                             \n",
       "2022-01-01 00:00:00     2.756100     1.467071     0.673547     2.566082\n",
       "2022-01-01 01:00:00     1.264705     0.764807     0.180366     0.715912"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[diff_features].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "      <th>num_trades</th>\n",
       "      <th>avg_vol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:00</th>\n",
       "      <td>-0.589950</td>\n",
       "      <td>-0.642011</td>\n",
       "      <td>-0.167248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 01:00:00</th>\n",
       "      <td>-0.672438</td>\n",
       "      <td>-0.689971</td>\n",
       "      <td>-0.907511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       volume  num_trades   avg_vol\n",
       "Unnamed: 0                                         \n",
       "2022-01-01 00:00:00 -0.589950   -0.642011 -0.167248\n",
       "2022-01-01 01:00:00 -0.672438   -0.689971 -0.907511"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[other_features].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 01:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     hour  day  day_of_week  month  year\n",
       "Unnamed: 0                                              \n",
       "2022-01-01 00:00:00     0    1            5      1     0\n",
       "2022-01-01 01:00:00     1    1            5      1     0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[time_features].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_other = torch.Tensor(df[other_features].to_numpy()).to(dtype)\n",
    "X_train_price = torch.Tensor(df[prices_features].to_numpy()).to(dtype)\n",
    "X_train_diff = torch.Tensor(df[diff_features].to_numpy()).to(dtype)\n",
    "X_train_time = torch.Tensor(df[time_features].to_numpy()).to(torch.int)\n",
    "y = torch.Tensor(df[target].to_numpy()).to(dtype)\n",
    "len_history = 512\n",
    "data = {'y': y, 'price': X_train_price, 'diff': X_train_diff, 'other': X_train_other, 'time': X_train_time}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_dim, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(hidden_dim, head_size, bias=False)\n",
    "        self.query = nn.Linear(hidden_dim, head_size, bias=False)\n",
    "        self.value = nn.Linear(hidden_dim, head_size, bias=False)\n",
    "        #self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * (k.shape[-1]**-0.5) # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        #wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        #wei = self.dropout(wei) # randomly prevent some of the nodes to communicate\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    # masked MultiHeadAttention in the article\n",
    "        #self.sa_heads = MultiHeadAttention(4, hidden_dim // 4) # i.e. 4 heads of 8-dim self-attention; \n",
    "        # similar to conv, instead of having 1 big conv, we have bigger number of smaller ones;\n",
    "    def __init__(self, num_heads, head_size, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(Head(hidden_dim, head_size) for _ in range(num_heads))\n",
    "        self.proj = nn.Linear(hidden_dim, hidden_dim) # just a linear transformation of the outcome\n",
    "        # it's the projection back to the residual pathway\n",
    "        #self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim = -1)\n",
    "        out = self.proj(out)#self.dropout(self.proj(out))\n",
    "        return out\n",
    "    \n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "    # Feed Forward in the article)\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 4  * hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * hidden_dim, hidden_dim), # it's the projection back to the residual pathway\n",
    "            #nn.Dropout(dropout), # before res con right before the res goes back to the res path way\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "    def __init__(self, hidden_dim, n_head):\n",
    "        # hidden_dim: embedding dim, n_head: number of heads we would like\n",
    "        # self attention is the communication\n",
    "        # all tokens do that independently, so multihead att gathered all the data \n",
    "        # now ffwd will think on that data individually - ffrd\n",
    "\n",
    "        \"\"\"\n",
    "        about the res con:\n",
    "        you can do some computation and then add it to the original feature\n",
    "        so you are going from the inputs to the targets only via plus and plus and plus\n",
    "        it's good, because + distributes gradients equally to both of it's brances\n",
    "        it's super usefull for you optimization\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        head_size = hidden_dim // n_head # will become 8\n",
    "        self.sa = MultiHeadAttention(n_head, head_size, hidden_dim)\n",
    "        self.ffwd = FeedForward(hidden_dim)\n",
    "        self.ln1 = nn.LayerNorm(hidden_dim) # makes features unit gausiian in initialisation\n",
    "        self.ln2 = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x)) # skip connections: we fork off, doing some computations, and come back\n",
    "        x = x + self.ffwd(self.ln2(x)) # difference with paper, before ffwd, not after in current 5 years\n",
    "        return x\n",
    "    \n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, n_head, n_layer):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.Sequential(*[Block(hidden_dim, n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(hidden_dim)\n",
    "        self.lm_head = nn.Linear(hidden_dim, 1) # from token emds to the logits; (B, T, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # integers from 0 to T-1 = torch.arange(T)\n",
    "        x = self.blocks(x)\n",
    "        #print(x.shape) 128, 512, 64\n",
    "        x = self.ln_f(x)\n",
    "        #print(x.shape) # 128, 512, 64\n",
    "        x = x.mean(1)\n",
    "        #print(x.shape) # 128, 64\n",
    "        x = self.lm_head(x)\n",
    "        #print(x.shape) # 128, 1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projector(nn.Module):\n",
    "    def __init__(self, hidden_dim, len_history, device=device, layer_norm=True):\n",
    "        super().__init__()\n",
    "        # Fully connected layer\n",
    "        self._len_history = len_history\n",
    "        self._hour_emb = nn.Embedding(24, hidden_dim)\n",
    "        self._day_emb = nn.Embedding(32, hidden_dim)\n",
    "        self._day_week = nn.Embedding(7, hidden_dim)\n",
    "        self._month = nn.Embedding(13, hidden_dim)\n",
    "        self._year = nn.Embedding(3, hidden_dim)\n",
    "        self._position_emb = nn.Embedding(len_history, hidden_dim)\n",
    "        self._price_linear = nn.Linear(4, hidden_dim)\n",
    "        self._diff_linear = nn.Linear(4, hidden_dim)\n",
    "        self._other_linear = nn.Linear(3, hidden_dim)\n",
    "        self._ln = nn.Identity()\n",
    "        if layer_norm:\n",
    "            self._ln = nn.LayerNorm(hidden_dim)\n",
    "        \n",
    "        self._init_weights()\n",
    "        self._device = device\n",
    "\n",
    "    def _init_weights(self):\n",
    "        nn.init.trunc_normal_(self._hour_emb.weight)\n",
    "        nn.init.trunc_normal_(self._day_emb.weight)\n",
    "        nn.init.trunc_normal_(self._day_week.weight)\n",
    "        nn.init.trunc_normal_(self._month.weight)\n",
    "        nn.init.trunc_normal_(self._year.weight)\n",
    "        nn.init.trunc_normal_(self._position_emb.weight)\n",
    "\n",
    "        nn.init.trunc_normal_(self._price_linear.weight)\n",
    "        nn.init.trunc_normal_(self._diff_linear.weight)\n",
    "        nn.init.trunc_normal_(self._other_linear.weight)\n",
    "    \n",
    "    def _forward_time(self, x):\n",
    "        hours = self._hour_emb(x[:, :, 0])\n",
    "        days = self._day_emb(x[:, :, 1])\n",
    "        week_day = self._day_week(x[:, :, 2])\n",
    "        month = self._month(x[:, :, 3])\n",
    "        year = self._year(x[:, :, 4])\n",
    "        out = year + hours + days + week_day + month\n",
    "        return out\n",
    "    \n",
    "    def _forward_position(self, x):\n",
    "        out = self._position_emb(x)\n",
    "        return out\n",
    "    \n",
    "    def _forward_price(self, x):\n",
    "        #print(x.shape) 128, 512, 4\n",
    "        x = self._price_linear(x)\n",
    "        return x\n",
    "\n",
    "    def _forward_diff(self, x):\n",
    "        #print(x.shape) 128, 512, 4\n",
    "        x = self._diff_linear(x)\n",
    "        return x\n",
    "\n",
    "    def _forward_other(self, x):\n",
    "        #print(x.shape) 128, 512, 3\n",
    "        x = self._other_linear(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #x_pos = torch.tensor(range(self._len_history-1, -1, -1)).to(self._device)\n",
    "        #x_pos = x_pos.repeat(x['price'].shape[0]).view(x['price'].shape[0], self._len_history)\n",
    "        #out_pos = self._forward_position(x_pos)\n",
    "        #out_time = self._forward_time(x['time'])\n",
    "        out_price = self._forward_price(x['price'])\n",
    "        out_diff = self._forward_diff(x['diff'])\n",
    "        out_other = self._forward_other(x['other'])\n",
    "        #out = out_pos + out_time + \n",
    "        out = out_price + out_diff + out_other\n",
    "        return out\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, len_history, device=device, layer_norm=True):\n",
    "        super().__init__()\n",
    "        # Fully connected layer\n",
    "        self._len_history = len_history\n",
    "        self._lin1 = nn.Linear(hidden_dim*len_history, hidden_dim)\n",
    "        self._lin2 = nn.Linear(hidden_dim, 1)\n",
    "        self._tanh = nn.Tanh()\n",
    "        self._init_weights()\n",
    "        self._device = device\n",
    "\n",
    "    def _init_weights(self):\n",
    "        nn.init.trunc_normal_(self._lin1.weight)\n",
    "        nn.init.trunc_normal_(self._lin2.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self._lin1(x.view(x.shape[0], -1))\n",
    "        out = self._tanh(out)\n",
    "        out = self._lin2(out)\n",
    "        return out\n",
    "    \n",
    "class TraiderModel(nn.Module):\n",
    "    def __init__(self, len_history, hidden_dim, device):\n",
    "        super().__init__()\n",
    "        self._projector_model = Projector(hidden_dim, len_history, device)\n",
    "        self._encoder_model = TransformerEncoder(hidden_dim, n_head=4, n_layer=2)\n",
    "        #self._encoder_model = Encoder(hidden_dim+11, len_history=len_history, device = device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self._projector_model(x) #128,512,64\n",
    "        out = self._encoder_model(out) #128,1\n",
    "        #out = x['price'][:, -1, 0].view(-1, 1) + out\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, \n",
    "                 data, \n",
    "                 n_epochs, \n",
    "                 len_history, \n",
    "                 hidden_dim, \n",
    "                 device, \n",
    "                 batch_size,\n",
    "                 target_scaller,\n",
    "                 n_eval=1440,\n",
    "                 lr=1e-3, \n",
    "                 weight_decay=1e-6, \n",
    "                 need_to_print_loss=False,\n",
    "                 max_iterations_per_epoch=None,\n",
    "                 ):\n",
    "        \n",
    "        self._n_epochs = n_epochs\n",
    "        self._max_iterations = max_iterations_per_epoch\n",
    "        self._batch_size = batch_size\n",
    "        self._n_eval = n_eval\n",
    "        self._len_history = len_history\n",
    "        self._device = device\n",
    "        self._model = TraiderModel(len_history, hidden_dim, self._device).to(self._device)\n",
    "        self._loss = nn.MSELoss(reduction=\"mean\").to(self._device)\n",
    "        self._optimizer = torch.optim.Adam(self._model.parameters(), lr=lr)\n",
    "        self._lr_scheduller = LinearLR(self._optimizer, start_factor=0.8, total_iters=self._n_epochs)\n",
    "        self._target_scaller = target_scaller\n",
    "        self._need_to_print_loss = need_to_print_loss\n",
    "\n",
    "        self.data_train = {key: data[key][:-self._n_eval] for key in data.keys()}\n",
    "        self.data_eval = {key: data[key][-self._n_eval - self._len_history:] for key in data.keys()}\n",
    "        self.feature_names = [key for key in data.keys() if key != 'y']\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(1, self._n_epochs+1):\n",
    "            print(f'epoch {epoch}')\n",
    "            cur_epoch_losses = self._train_one_epoch()\n",
    "            print(f'epoch {epoch} done, loss is {round(sum(cur_epoch_losses), 2)}')\n",
    "            eval_loss = self._eval_batch(batch_size=self._n_eval)\n",
    "            print(f'epoch {epoch} done, validation loss is {round(eval_loss, 2)}')\n",
    "            self._lr_scheduller.step()\n",
    "\n",
    "    def _train_one_epoch(self):\n",
    "        self._model.train()\n",
    "        i = 0\n",
    "        num_iterations = 0\n",
    "        losses = list()\n",
    "        while self.data_train['y'].shape[0] - i - len_history > self._batch_size:\n",
    "            loss_value = self._train_batch(i, self._batch_size)\n",
    "            losses.append(loss_value)\n",
    "            i += self._batch_size\n",
    "            num_iterations += 1\n",
    "            if self._need_to_print_loss and num_iterations%1000==0:\n",
    "                print(f'{round(i/self.data_train[\"y\"].shape[0]*100)}% are done', f'loss={loss_value}')\n",
    "            if self._max_iterations:\n",
    "                if num_iterations > self._max_iterations:\n",
    "                    return losses\n",
    "        #last batch training\n",
    "        loss_value = self._train_batch(i, self.data_train['y'].shape[0] - i - len_history)\n",
    "        losses.append(loss_value)\n",
    "        return losses\n",
    "\n",
    "    def _train_batch(self, i, batch_size):\n",
    "        targets = self.data_train['y'][i+self._len_history-1:i+self._len_history+batch_size-1].to(self._device)\n",
    "        features_batch = {}\n",
    "        for key in self.feature_names:\n",
    "            features = self.data_train[key][i:i+self._len_history+batch_size]\n",
    "            features_batch[key] = torch.zeros((batch_size, self._len_history, features.shape[-1]), dtype=features.dtype)\n",
    "            for j in range(batch_size):\n",
    "                features_batch[key][j] = features[j:j+self._len_history]\n",
    "            features_batch[key] = features_batch[key].to(self._device)\n",
    "        prices_predicted = self._model(features_batch).squeeze(1)\n",
    "        self._optimizer.zero_grad()\n",
    "        loss = self._loss(targets, prices_predicted)\n",
    "        loss.backward()\n",
    "        self._optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def _eval_batch(self, batch_size):\n",
    "        features_batch = {}\n",
    "        for key in self.feature_names:\n",
    "            features = self.data_eval[key][:self._len_history+batch_size]\n",
    "            features_batch[key] = torch.zeros((batch_size, self._len_history, features.shape[-1]), dtype=features.dtype)\n",
    "            for j in range(batch_size):\n",
    "                features_batch[key][j] = features[j:j+self._len_history]\n",
    "            features_batch[key] = features_batch[key].to(self._device)\n",
    "        \n",
    "        prices_predicted = self._model(features_batch).squeeze(1).detach().cpu()\n",
    "        targets_for_eval = self.data_eval['y'][self._len_history-1:self._len_history+batch_size-1]\n",
    "        return np.abs(prices_predicted - targets_for_eval).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "epoch 1 done, loss is nan\n",
      "epoch 1 done, validation loss is nan\n",
      "old_price_pred: 0.020168164744973183\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "                  data=data,\n",
    "                  n_epochs=1,\n",
    "                  len_history=len_history, \n",
    "                  hidden_dim=64,\n",
    "                  device=device,\n",
    "                  batch_size=32,\n",
    "                  target_scaller=scaler_price,\n",
    "                  n_eval=24,\n",
    "                  lr=3e-4,\n",
    "                  max_iterations_per_epoch=None,\n",
    "                  need_to_print_loss=True\n",
    "                  )\n",
    "trainer.train()\n",
    "\n",
    "print(f'old_price_pred: {np.abs(trainer.data_eval[\"price\"][len_history:, 0] - trainer.data_eval[\"y\"][len_history:, 0]).mean().item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/koshirshov/koshirshov/Programming_and_algo/Web/testing_bynance.ipynb Cell 16\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/koshirshov/koshirshov/Programming_and_algo/Web/testing_bynance.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m12\u001b[39m,\u001b[39m8\u001b[39m))\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/koshirshov/koshirshov/Programming_and_algo/Web/testing_bynance.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(dates, preds, color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mblue\u001b[39m\u001b[39m'\u001b[39m, marker\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mo\u001b[39m\u001b[39m'\u001b[39m, linestyle\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdashed\u001b[39m\u001b[39m'\u001b[39m, linewidth\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, markersize\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/koshirshov/koshirshov/Programming_and_algo/Web/testing_bynance.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(dates, targets, color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mblack\u001b[39m\u001b[39m'\u001b[39m, linewidth\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, markersize\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/koshirshov/koshirshov/Programming_and_algo/Web/testing_bynance.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(dates, prev_targets, color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mred\u001b[39m\u001b[39m'\u001b[39m, marker\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mo\u001b[39m\u001b[39m'\u001b[39m, linestyle\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdashed\u001b[39m\u001b[39m'\u001b[39m, linewidth\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, markersize\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dates' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(dates, preds, color='blue', marker='o', linestyle='dashed', linewidth=2, markersize=1)\n",
    "plt.plot(dates, targets, color='black', linewidth=1, markersize=1)\n",
    "plt.plot(dates, prev_targets, color='red', marker='o', linestyle='dashed', linewidth=0.2, markersize=1)\n",
    "plt.title(f'loss = {np.abs(preds - targets).mean()}')\n",
    "plt.ylim(targets.min()-300, targets.max()+300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch 53 done, loss is 100.42\n",
    "epoch 53 done, validation loss is 0.29\n",
    "epoch 54\n",
    "epoch 54 done, loss is 91.77\n",
    "epoch 54 done, validation loss is 0.09\n",
    "epoch 55\n",
    "epoch 55 done, loss is 103.77\n",
    "epoch 55 done, validation loss is 0.36\n",
    "epoch 56\n",
    "epoch 56 done, loss is 82.57\n",
    "epoch 56 done, validation loss is 0.08\n",
    "epoch 57\n",
    "epoch 57 done, loss is 100.27\n",
    "epoch 57 done, validation loss is 0.09"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
